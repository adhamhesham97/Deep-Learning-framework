{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMZADwPC3qb98jEwC/6KuwM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adhamhesham97/Deep-Learning-framework/blob/main/Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myasRXT0XEa6"
      },
      "source": [
        "pip install mshtensorflow --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDKYgtgDRp8W"
      },
      "source": [
        "import mshtensorflow as DL\r\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAOECc-r3AvT"
      },
      "source": [
        "# download and load dataset\n",
        "\n",
        "Label_Train,Features_Train,Label_Test,Features_Test = DL.download_and_read('CIFAR')\n",
        "Label_Train,Features_Train,Label_Test,Features_Test = DL.download_and_read('MNIST')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoQdDT7GTuip"
      },
      "source": [
        "# CONVOLUTIONAL NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYvJkc_2UnHc"
      },
      "source": [
        "#%% load dataset\r\n",
        " \r\n",
        "# load dataset\r\n",
        "Label_Train, Features_Train, Label_Test, Features_Test = DL.ReadFile(\"./MNIST\")\r\n",
        "#Label_Train, Features_Train, Label_Test, Features_Test = DL.ReadFile(\"./CIFAR/cifar-10-batches-py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4r97q3iXtL3"
      },
      "source": [
        "#%% training\n",
        " \n",
        "batch_size = 128\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "hidden_units = 100\n",
        " \n",
        "input_dimensions = (28, 28, 1)\n",
        " \n",
        "# change each label from scaler value to vector( 2 ---> [0, 0, 1, 0, 0, ...] ) (hot one)\n",
        "Label_Train_hotone = DL.hot_one(Label_Train, num_classes)\n",
        " \n",
        "'''\n",
        "conv parameters:\n",
        "Filter_size, num_of_filters, Stride, padding, activation_type\n",
        " \n",
        "pool parameters:\n",
        "Filter_size, Stride\n",
        "'''\n",
        " \n",
        "model = DL.model()\n",
        "model.input_dims(input_dimensions)\n",
        " \n",
        "# LeNet-5\n",
        "model.add('conv', (5, 5), 6, 1, 0, \"Relu\")\n",
        "model.add('maxpool', (2, 2), 2)\n",
        "model.add('conv', (5, 5), 16, 1, 0, \"Relu\")\n",
        "model.add('maxpool', (2, 2), 2)\n",
        "model.add('flatten')\n",
        "model.add('Relu', 120)\n",
        "model.add('Relu', 84)\n",
        "model.add('Linear', num_classes)\n",
        " \n",
        "# optim = DL.optimizer('gd',0.1, 0.99)\n",
        "optim = DL.optimizer('adam',0.001)\n",
        "loss_fn = DL.loss_Function('SoftmaxCrossEntropy')\n",
        "loss_fn.setLambda(0)\n",
        " \n",
        "model.fit(Features_Train, Label_Train_hotone,\n",
        "          batch_size, num_epochs, optim, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP9nASY7ZdtC"
      },
      "source": [
        " #%% testing\n",
        " \n",
        "# test on the same trained data set\n",
        "predicted_labels = np.argmax(model.predict(Features_Train[0:5000]), axis=0)\n",
        "accuracy = DL.accuracy(predicted_labels, Label_Train)\n",
        "print(\"Accuracy of training dataset = {:.2f}%\".format(accuracy*100))\n",
        " \n",
        "# test on the test data set\n",
        "predicted_labels = np.argmax(model.predict(Features_Test), axis=0)\n",
        "accuracy = DL.accuracy(predicted_labels, Label_Test)\n",
        "print(\"Model Accuracy = {:.2f}%\".format(accuracy*100))\n",
        " \n",
        "DL.sample_visualization(True, Label_Test, Features_Test, predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsbwLlKAFPZ8"
      },
      "source": [
        " #%% store and load model\n",
        "\n",
        "DL.store(model, \"CNN MNIST model\") # store\n",
        "\n",
        "# model = DL.load(\"CNN MNIST model\") #"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzjatKD_TKe7"
      },
      "source": [
        "#FULLY CONNECTED NN\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJxyS1KLUddV"
      },
      "source": [
        "#%% load dataset\r\n",
        " \r\n",
        "# load dataset\r\n",
        "# Label_Train, Features_Train, Label_Test, Features_Test = DL.ReadFile(\"./MNIST\")\r\n",
        "Label_Train, Features_Train, Label_Test, Features_Test = DL.ReadFile(\"./CIFAR/cifar-10-batches-py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIVWAFxaUJ74"
      },
      "source": [
        "#%% training\r\n",
        "batch_size = 128\r\n",
        "num_epochs = 10\r\n",
        "num_classes = 10\r\n",
        "hidden_units = 100\r\n",
        "\r\n",
        "input_dimensions = (32, 32, 3)\r\n",
        "\r\n",
        "# change each label from scaler value to vector( 2 ---> [0, 0, 1, 0, 0, ...] ) (hot one)\r\n",
        "Label_Train_hotone = DL.hot_one(Label_Train, num_classes)\r\n",
        "\r\n",
        "model = DL.model()\r\n",
        "model.input_dims(input_dimensions)\r\n",
        "model.add('flatten')\r\n",
        "model.add('Relu', hidden_units)\r\n",
        "model.add('Linear', num_classes)\r\n",
        "# optim = DL.optimizer('gd', 0.5, 0.5)\r\n",
        "optim = DL.optimizer('adam', 0.0001)\r\n",
        "loss_fn = DL.loss_Function('SoftmaxCrossEntropy')\r\n",
        "loss_fn.setLambda(0)\r\n",
        "\r\n",
        "model.fit(Features_Train, Label_Train_hotone,\r\n",
        "          batch_size, num_epochs, optim, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LHkkiBvUHRz"
      },
      "source": [
        "#%% testing\r\n",
        "\r\n",
        "# test on the same trained data set\r\n",
        "predicted_labels = np.argmax(model.predict(Features_Train), axis=0)\r\n",
        "accuracy = DL.accuracy(predicted_labels, Label_Train)\r\n",
        "print(\"Accuracy of training dataset = {:.2f}%\".format(accuracy*100))\r\n",
        "\r\n",
        "# test on the test data set\r\n",
        "predicted_labels = np.argmax(model.predict(Features_Test), axis=0)\r\n",
        "accuracy = DL.accuracy(predicted_labels, Label_Test)\r\n",
        "print(\"Model Accuracy = {:.2f}%\".format(accuracy*100))\r\n",
        "\r\n",
        "DL.sample_visualization(False, Label_Test, Features_Test, predicted_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0nR5AvFTQ--"
      },
      "source": [
        "#%% store and load model\r\n",
        "\r\n",
        "DL.store(model, \"FC CIFAR model\") # store\r\n",
        "\r\n",
        "# model = DL.load(\"FC CIFAR model\") # load"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMsDlNsEUs2V"
      },
      "source": [
        "# FULLY CONNECTED NN (using PCA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_I9NSx8VHm2"
      },
      "source": [
        "#%% load dataset\r\n",
        " \r\n",
        "# load dataset\r\n",
        "Label_Train, Features_Train, Label_Test, Features_Test = DL.ReadFile(\"./MNIST\")\r\n",
        "#Label_Train, Features_Train, Label_Test, Features_Test = DL.ReadFile(\"./CIFAR/cifar-10-batches-py\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIVpctFfUsI2"
      },
      "source": [
        "#%% using PCA to reduce dimensions\r\n",
        "Features_Train_flattened=Features_Train.reshape(60000,28*28)\r\n",
        "Features_Test_flattened=Features_Test.reshape(10000,28*28)\r\n",
        "pca=DL.PCA(0.98)\r\n",
        "pca.fit(Features_Train_flattened)\r\n",
        "Features_Train_reduced = pca.transform(Features_Train_flattened)\r\n",
        "Features_Test_reduced = pca.transform(Features_Test_flattened)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7sYLQY1VIsp"
      },
      "source": [
        "#%% training\r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "num_epochs = 10\r\n",
        "num_classes = 10\r\n",
        "hidden_units = 300\r\n",
        "\r\n",
        "Label_Train_hotone = DL.hot_one(Label_Train, num_classes)\r\n",
        "input_dimensions=Features_Train_reduced.shape[0]\r\n",
        "model = DL.model()\r\n",
        "model.input_dims(input_dimensions)\r\n",
        "model.add('Relu', hidden_units)\r\n",
        "model.add('Linear', num_classes)\r\n",
        "optim = DL.optimizer('gd',0.2,0.2)\r\n",
        "loss_fn = DL.loss_Function('SoftmaxCrossEntropy')\r\n",
        "loss_fn.setLambda(0)\r\n",
        "model.fit(Features_Train_reduced, Label_Train_hotone,batch_size, num_epochs, optim, loss_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KgWoIn5NVS8e"
      },
      "source": [
        "#%% testing\r\n",
        "\r\n",
        "# test on the same trained data\r\n",
        "predicted_labels = np.argmax(model.predict((Features_Train_reduced)), axis=0)\r\n",
        "accuracy = DL.accuracy(predicted_labels, Label_Train)\r\n",
        "print(\"Accuracy of training dataset = {:.2f}%\".format(accuracy*100))\r\n",
        "\r\n",
        "# test on the test data set\r\n",
        "Features_Test_reduced = pca.transform(Features_Test_flattened)\r\n",
        "predicted_labels = np.argmax(model.predict(Features_Test_reduced), axis=0)\r\n",
        "accuracy = DL.accuracy(predicted_labels, Label_Test)\r\n",
        "print(\"Model Accuracy = {:.2f}%\".format(accuracy*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9kGu7dBVaBY"
      },
      "source": [
        "#%% store and load model\r\n",
        "\r\n",
        "DL.store(model, \"FC(PCA) MNIST model\") # store\r\n",
        "# model = DL.load(\"FC MNIST model\") # load"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}